{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interfacing *torch* to *heyoka.py*\n",
    "\n",
    "```{note}\n",
    "For an introduction on neural networks in *heyoka.py*, check out the tutorial: [Feed-Forward Neural Networks](<./ffnn.ipynb>).\n",
    "```\n",
    "\n",
    "\n",
    "```{warning}\n",
    "This tutorial assumes [torch](https://pytorch.org/) is installed\n",
    "```\n",
    "\n",
    "*heyoka.py* is not a library meant for machine learning, nor it aspires to be one. However, given its support for feed-forward neural networks and their potential use in numerical integration, it might be useful to have a way to construct a `ffnn` from a torch model. This tutorial tackles this!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "#we use float64 as heyoka\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "class torch_net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=4,\n",
    "        hidden_layer_dims=[32, 32],\n",
    "        output_dim=1,\n",
    "        activation=nn.Tanh(),\n",
    "    ):\n",
    "        super(torch_net, self).__init__()\n",
    "\n",
    "        dims = [input_dim] + hidden_layer_dims\n",
    "\n",
    "        self.fcs = nn.ModuleList(\n",
    "            [nn.Linear(dims[i], dims[i + 1]) for i in range(len(dims) - 1)]\n",
    "        )\n",
    "\n",
    "        self.act = activation\n",
    "        self.acts = nn.ModuleList([self.act for _ in range(len(dims) - 1)])\n",
    "        self.fc_out = nn.Linear(dims[-1], output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for fc, act in zip(self.fcs, self.acts):\n",
    "            x = act(fc(x))\n",
    "        return self.act(self.fc_out(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a function that takes the `torch` weights and biases, and returns them in a format that is compatible with `heyoka.ffnn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def weights_and_biases_heyoka(model):\n",
    "    weights = {}\n",
    "    biases = {}\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            weights[name] = param.data.clone()\n",
    "        elif 'bias' in name:\n",
    "            biases[name] = param.data.clone()\n",
    "    biases_torch=[]\n",
    "    weights_torch=[]\n",
    "    for idx in range(len(weights)):\n",
    "        weights_torch.append(weights[list(weights.keys())[idx]].numpy())\n",
    "        biases_torch.append(biases[list(biases.keys())[idx]].numpy())\n",
    "        \n",
    "    w_flat=[]\n",
    "    b_flat=[]\n",
    "    for i in range(len(weights_torch)):\n",
    "        w_flat+=list(weights_torch[i].flatten())\n",
    "        b_flat+=list(biases_torch[i].flatten())\n",
    "    w_flat=np.array(w_flat)\n",
    "    b_flat=np.array(b_flat)\n",
    "    print(w_flat.shape)\n",
    "    return np.concatenate((w_flat, b_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now instantiate the model and extract its weights and biases ready for constructing an `heyoka.ffnn` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1184,)\n"
     ]
    }
   ],
   "source": [
    "model = torch_net(input_dim=4, \n",
    "                  hidden_layer_dims=[32, 32],\n",
    "                  output_dim=1,\n",
    "                  activation=nn.Tanh())\n",
    "flattened_weights = weights_and_biases_heyoka(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate the feed forward neural network in *heyoka.py* using those parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heyoka as hk\n",
    "\n",
    "inp_1, inp_2, inp_3, inp_4=hk.make_vars(\"inp_1\",\"inp_2\",\"inp_3\",\"inp_4\")\n",
    "model_heyoka=hk.model.ffnn(inputs=[inp_1, inp_2, inp_3, inp_4], \n",
    "                           nn_hidden=[32,32], \n",
    "                           n_out=1,\n",
    "                           activations=[hk.tanh,hk.tanh,hk.tanh], \n",
    "                           nn_wb=flattened_weights)\n",
    "model_heyoka_compiled=hk.make_cfunc(model_heyoka)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! How do we now verify the output is the same at inference? Let's generate some random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input=torch.rand((4,1000000))\n",
    "random_input_torch=random_input.t()\n",
    "random_input_numpy=random_input.numpy()\n",
    "out_array=np.zeros((1,1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare the output of `heyoka.ffnn` and `torch` to see if they are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25788307, -0.21975401, -0.26027468, ..., -0.2427392 ,\n",
       "        -0.24344253, -0.18246564]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_heyoka_compiled(random_input_numpy,outputs=out_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2579],\n",
       "        [-0.2198],\n",
       "        [-0.2603],\n",
       "        ...,\n",
       "        [-0.2427],\n",
       "        [-0.2434],\n",
       "        [-0.1825]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(random_input_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way we have managed to port the *torch* model in *heyoka.py*, reproducing the same results... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_drag_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
